const e="Bias Detection Guide",n=[{title:"Confirmation Bias",content:`What it is: Seeking or interpreting information that confirms pre-existing beliefs.

How to detect:
• Are you only highlighting findings that support your hypothesis?
• Did you dismiss contradictory evidence too quickly?
• Are stakeholders only interested in certain outcomes?

How to avoid:
• Actively seek disconfirming evidence
• Include devil's advocate in analysis sessions
• Document all findings, not just supportive ones
• Use structured analysis frameworks`},{title:"Selection Bias",content:`What it is: Participants don't represent your actual user base.

How to detect:
• Is your sample too homogeneous?
• Are certain user groups over/underrepresented?
• Did recruitment methods exclude certain populations?

How to avoid:
• Define clear recruitment criteria
• Use multiple recruitment channels
• Track participant demographics
• Consider edge cases and extreme users`},{title:"Anchoring Bias",content:`What it is: Over-relying on the first piece of information encountered.

How to detect:
• Are early findings dominating your analysis?
• Is one memorable quote overshadowing patterns?
• Did initial assumptions go unchallenged?

How to avoid:
• Randomize order of data review
• Weight all evidence equally
• Challenge initial interpretations
• Use systematic coding methods`},{title:"Social Desirability Bias",content:`What it is: Participants give answers they think you want to hear.

How to detect:
• Answers seem too positive or agreeable
• Behavior doesn't match stated preferences
• Participants reluctant to criticize

How to avoid:
• Use indirect questioning techniques
• Observe behavior, not just opinions
• Create safe space for honest feedback
• Triangulate with multiple data sources`},{title:"Recency Bias",content:`What it is: Giving more weight to recent events or last participants.

How to detect:
• Final sessions influencing conclusions disproportionately
• Earlier insights being forgotten
• Recent examples dominating recommendations

How to avoid:
• Document insights immediately
• Review all sessions before analysis
• Use structured note-taking
• Create rolling synthesis documents`},{title:"Framing Bias",content:`What it is: How questions are asked influences responses.

How to detect:
• Leading questions in your protocol
• Assumptions built into question wording
• Binary choices limiting responses

How to avoid:
• Use open-ended questions
• Pilot test question wording
• Ask same concept multiple ways
• Let participants use their own words`},{title:"Availability Heuristic",content:`What it is: Overestimating importance of easily recalled information.

How to detect:
• Vivid examples dominating analysis
• Edge cases seeming more common
• Dramatic moments overshadowing patterns

How to avoid:
• Count frequency systematically
• Look for patterns, not just memorable moments
• Use affinity mapping techniques
• Validate with quantitative data`},{title:"Bias Mitigation Checklist",content:`Before research:
□ Diverse research team assembled
□ Assumptions documented
□ Protocol reviewed for leading questions

During research:
□ Consistent process followed
□ All participants treated equally
□ Observer notes kept separate

During analysis:
□ Multiple coders involved
□ Contradictions explored
□ Patterns quantified
□ Confidence levels noted

Reporting:
□ Limitations acknowledged
□ Methodology transparent
□ Alternative interpretations considered`}],t={title:e,sections:n};export{t as default,n as sections,e as title};
